{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch, torchvision\nfrom torchvision.transforms import ToTensor, Normalize, Compose\nfrom torchvision import datasets\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nfrom IPython.display import Image\nfrom torchvision.utils import save_image\nimport random\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-27T16:02:51.175887Z","iopub.execute_input":"2021-12-27T16:02:51.176430Z","iopub.status.idle":"2021-12-27T16:02:52.943075Z","shell.execute_reply.started":"2021-12-27T16:02:51.176376Z","shell.execute_reply":"2021-12-27T16:02:52.942340Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/az-handwritten-alphabets-in-csv-format/A_Z Handwritten Data.csv\").astype('float32')","metadata":{"execution":{"iopub.status.busy":"2021-12-27T16:14:50.227463Z","iopub.execute_input":"2021-12-27T16:14:50.228070Z","iopub.status.idle":"2021-12-27T16:15:12.871278Z","shell.execute_reply.started":"2021-12-27T16:14:50.228030Z","shell.execute_reply":"2021-12-27T16:15:12.870531Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"indexes = {\n    \"a\": (0, 13869), #13869 values\n    \"b\": (13869, 22538), #8668\n    \"c\": (22538, 45947), #23409\n    \"d\": (45947, 56081), #10134\n    \"e\": (56081, 67521), #11440\n    \"f\": (67521, 68684), #1163,\n    \"g\": (68684, 74446), #5762\n    \"h\": (74446, 81664), #7218\n    \"i\": (81664, 82784), #1120,\n    \"j\": (82784, 91277), #8493,\n    \"k\": (91277, 96880), #5603,\n    \"l\": (96880, 108466), #11586,\n    \"m\": (108466, 120802), #12336,\n    \"n\": (120802, 139812), #19010,\n    \"o\": (139812, 197637), #57825,\n    \"p\": (197637, 216978), #19341,\n    \"q\": (216978, 222790), #5812,\n    \"r\": (222790, 234356), #11566,\n    \"s\": (234356, 282775), #48419,\n    \"t\": (282775, 305270), #22495,\n    \"u\": (305270, 334278), #29008,\n    \"v\": (334278, 338460), #4182,\n    \"w\": (338460, 349244), #10784,\n    \"x\": (349244, 355516), #6272,\n    \"y\": (355516, 366375), #10859,\n    \"z\": (366375, 372451), #6076,\n}\n\nabba = pd.concat((data.iloc[indexes[letter][0]:indexes[letter][1]].sample(frac = 1).iloc[:4182].iloc[:,1:] for letter in indexes), ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nX = abba.values\nX = X.reshape((abba.shape[0], 28, 28))\nX.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-27T16:15:12.912043Z","iopub.status.idle":"2021-12-27T16:15:12.912625Z","shell.execute_reply.started":"2021-12-27T16:15:12.912398Z","shell.execute_reply":"2021-12-27T16:15:12.912423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalization\nX = (X - 127.5) / 127.5","metadata":{"execution":{"iopub.status.busy":"2021-12-27T16:15:12.913926Z","iopub.status.idle":"2021-12-27T16:15:12.914326Z","shell.execute_reply.started":"2021-12-27T16:15:12.914110Z","shell.execute_reply":"2021-12-27T16:15:12.914132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_data(X):\n    plt.figure(figsize=(10, 10))\n    i = 1\n    for img in X[102651-5182:]:\n        print(\".\", end=\"\")\n        plt.subplot(10, 10, i)\n        plt.imshow(img.reshape((28, 28)), cmap=\"gray\")\n        i+=1\n        if i>100: \n            break\n    plt.show()\n    \nshow_data(X)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T16:15:12.915744Z","iopub.status.idle":"2021-12-27T16:15:12.916158Z","shell.execute_reply.started":"2021-12-27T16:15:12.915932Z","shell.execute_reply":"2021-12-27T16:15:12.915955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = torch.tensor(X)\nimg = X[random.randint(0, X.shape[0])]\nplt.imshow(img.squeeze(0), cmap=\"gray\")","metadata":{"execution":{"iopub.status.busy":"2021-12-27T16:15:12.917593Z","iopub.status.idle":"2021-12-27T16:15:12.918002Z","shell.execute_reply.started":"2021-12-27T16:15:12.917784Z","shell.execute_reply":"2021-12-27T16:15:12.917806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bs = 100\ndata_loader = DataLoader(X, bs, shuffle=True)\nshow_data(next(iter(data_loader)))\nnext(iter(data_loader)).shape","metadata":{"execution":{"iopub.status.busy":"2021-12-27T16:17:22.817756Z","iopub.execute_input":"2021-12-27T16:17:22.818009Z","iopub.status.idle":"2021-12-27T16:17:22.886780Z","shell.execute_reply.started":"2021-12-27T16:17:22.817978Z","shell.execute_reply":"2021-12-27T16:17:22.886131Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Helper Functions\ndef denorm(x):\n    out = (x + 1) / 2\n    return out.clamp(0, 1)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T16:17:24.590039Z","iopub.execute_input":"2021-12-27T16:17:24.590286Z","iopub.status.idle":"2021-12-27T16:17:24.594517Z","shell.execute_reply.started":"2021-12-27T16:17:24.590257Z","shell.execute_reply":"2021-12-27T16:17:24.593723Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n  device = torch.device(\"cuda\")\nelse:\n  device = torch.device(\"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-12-27T16:17:25.196122Z","iopub.execute_input":"2021-12-27T16:17:25.196821Z","iopub.status.idle":"2021-12-27T16:17:25.245328Z","shell.execute_reply.started":"2021-12-27T16:17:25.196780Z","shell.execute_reply":"2021-12-27T16:17:25.244547Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from torch.nn.modules.linear import Linear\nslope = 0.2 #for leakyReLU\nDnet = nn.Sequential( # Output is a single number 0-1\n    nn.Linear(784, 256),\n    nn.LeakyReLU(slope),\n    nn.Linear(256, 256),\n    nn.LeakyReLU(slope),\n    nn.Linear(256, 1),\n    nn.Sigmoid()\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T16:17:26.518183Z","iopub.execute_input":"2021-12-27T16:17:26.518595Z","iopub.status.idle":"2021-12-27T16:17:26.527661Z","shell.execute_reply.started":"2021-12-27T16:17:26.518560Z","shell.execute_reply":"2021-12-27T16:17:26.526952Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"Dnet.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T16:17:27.184264Z","iopub.execute_input":"2021-12-27T16:17:27.184754Z","iopub.status.idle":"2021-12-27T16:17:29.640560Z","shell.execute_reply.started":"2021-12-27T16:17:27.184718Z","shell.execute_reply":"2021-12-27T16:17:29.639146Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"latent_size=64\nGnet = nn.Sequential(\n    nn.Linear(latent_size, 256),\n    nn.ReLU(),\n    nn.Linear(256, 256),\n    nn.ReLU(),\n    nn.Linear(256, 784),\n    nn.Tanh() #This because we want -1 to 1 values\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T16:17:29.642219Z","iopub.execute_input":"2021-12-27T16:17:29.642487Z","iopub.status.idle":"2021-12-27T16:17:29.650970Z","shell.execute_reply.started":"2021-12-27T16:17:29.642451Z","shell.execute_reply":"2021-12-27T16:17:29.650292Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"Gnet.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T16:17:29.652330Z","iopub.execute_input":"2021-12-27T16:17:29.652604Z","iopub.status.idle":"2021-12-27T16:17:29.661454Z","shell.execute_reply.started":"2021-12-27T16:17:29.652568Z","shell.execute_reply":"2021-12-27T16:17:29.660652Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#Loss Function\ncriterion = nn.BCELoss() \n#Optimizers\ndnet_optimizer = torch.optim.Adam(Dnet.parameters(), lr=0.0002)\ngnet_optimizer = torch.optim.Adam(Gnet.parameters(), lr=0.0002)\n#Helper\ndef reset_grad(): # After every gradient dcent iteration, we need toreset the gradients\n  dnet_optimizer.zero_grad()\n  gnet_optimizer.zero_grad()","metadata":{"execution":{"iopub.status.busy":"2021-12-27T16:17:31.554547Z","iopub.execute_input":"2021-12-27T16:17:31.555205Z","iopub.status.idle":"2021-12-27T16:17:31.560057Z","shell.execute_reply.started":"2021-12-27T16:17:31.555171Z","shell.execute_reply":"2021-12-27T16:17:31.559137Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"\ndef train_discriminator(images):\n    # Calculate Real Loss \n    real_labels = torch.ones(bs, 1).to(device)\n    fake_labels = torch.zeros(bs, 1).to(device)\n    output = Dnet(images)\n    d_loss_real = criterion(output, real_labels)\n    real_score = output\n    # Calculate Fake Loss\n    fake_images = Gnet(torch.randn(bs, latent_size).to(device))\n    output = Dnet(fake_images)\n    d_loss_fake = criterion(output, fake_labels)\n    fake_score = output\n    # Calculate Total Loss\n    d_loss = d_loss_real + d_loss_fake\n    \n    # Gradient Decent\n    d_loss.backward()\n    dnet_optimizer.step()\n    reset_grad()\n    return d_loss, real_score, fake_score","metadata":{"execution":{"iopub.status.busy":"2021-12-27T16:17:35.229843Z","iopub.execute_input":"2021-12-27T16:17:35.230370Z","iopub.status.idle":"2021-12-27T16:17:35.236803Z","shell.execute_reply.started":"2021-12-27T16:17:35.230333Z","shell.execute_reply":"2021-12-27T16:17:35.236119Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def train_generator():\n    # Feedforward and Calculate Loss\n    fake_images = Gnet(torch.randn(bs, latent_size).to(device))\n    labels = torch.ones(bs, 1).to(device)\n    descriminator_thinks = Dnet(fake_images)\n    g_loss = criterion(descriminator_thinks, labels)\n  \n    # Gradient Decent\n    g_loss.backward()\n    gnet_optimizer.step()\n    reset_grad()\n    return g_loss, fake_images\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-27T16:18:45.037147Z","iopub.execute_input":"2021-12-27T16:18:45.037420Z","iopub.status.idle":"2021-12-27T16:18:45.042459Z","shell.execute_reply.started":"2021-12-27T16:18:45.037372Z","shell.execute_reply":"2021-12-27T16:18:45.041752Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import os\n\nfolder = 'samples'\nif not os.path.exists(folder):\n    os.makedirs(folder)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T16:21:11.418371Z","iopub.execute_input":"2021-12-27T16:21:11.419065Z","iopub.status.idle":"2021-12-27T16:21:11.423350Z","shell.execute_reply.started":"2021-12-27T16:21:11.419028Z","shell.execute_reply":"2021-12-27T16:21:11.422611Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\nfrom torchvision.utils import save_image\n\n# Save some real images\nfor images in data_loader:\n    images = images.reshape(images.size(0), 1, 28, 28)\n    save_image(denorm(images), os.path.join(folder, 'real_images.png'), nrow=10)\n    break\n   \nImage(os.path.join(folder, 'real_images.png'))","metadata":{"execution":{"iopub.status.busy":"2021-12-27T16:21:12.146932Z","iopub.execute_input":"2021-12-27T16:21:12.147198Z","iopub.status.idle":"2021-12-27T16:21:12.210650Z","shell.execute_reply.started":"2021-12-27T16:21:12.147166Z","shell.execute_reply":"2021-12-27T16:21:12.209844Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"sample_vectors = torch.randn(bs, latent_size).to(device)\n\ndef save_fake_images(index):\n    fake_images = Gnet(sample_vectors)\n    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n    fake_fname = 'fake_images-{0:0=4d}.png'.format(index)\n    print('Saving', fake_fname)\n    save_image(denorm(fake_images), os.path.join(folder, fake_fname), nrow=10)\n    Image('./samples/{}'.format(fake_fname))\n    return fake_fname\n# Before training\n\nImage(os.path.join(folder, save_fake_images(0)))","metadata":{"execution":{"iopub.status.busy":"2021-12-27T16:21:32.055822Z","iopub.execute_input":"2021-12-27T16:21:32.056074Z","iopub.status.idle":"2021-12-27T16:21:32.864751Z","shell.execute_reply.started":"2021-12-27T16:21:32.056045Z","shell.execute_reply":"2021-12-27T16:21:32.864067Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"%%time\nepochs = 450\ntotal_step = len(data_loader)\nd_losses, g_losses, real_scores, fake_scores = [], [], [], []\n\nfor epoch in range(epochs):\n    for i, images in enumerate(data_loader):\n        if images.shape[0] == bs:\n            images_vector = images.view(bs, -1).to(device)\n        else:\n            continue\n        d_loss, real_score, fake_score = train_discriminator(images_vector)\n        g_loss, fake_images = train_generator()\n        if (i+1) % 200 == 0:\n            d_losses.append(d_loss.item())\n            g_losses.append(g_loss.item())\n            real_scores.append(real_score.mean().item())\n            fake_scores.append(fake_score.mean().item())\n            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}'.format(epoch, epochs, i+1, total_step, d_loss.item(), g_loss.item(), real_score.mean().item(), fake_score.mean().item()))\n    save_fake_images(epoch+1)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-27T16:21:39.713928Z","iopub.execute_input":"2021-12-27T16:21:39.714542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 10))\nplt.plot(d_losses, '-')\nplt.plot(g_losses, '-')\nplt.xlabel('step')\nplt.ylabel('loss')\nplt.legend(['Discriminator', 'Generator'])\nplt.title('Losses');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Running an intrained GNet for fun\ny = Gnet(torch.randn(bs, latent_size).to(device)) #For 2 images\nreshaped_imgs = y.reshape(-1, 28, 28)\ngen_imgs = denorm(reshaped_imgs).detach()\nfor img in gen_imgs:\n    plt.imshow(gen_imgs[img].to(\"cpu\"), cmap=\"gray\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_vectors = torch.randn(bs, latent_size).to(device)\nImage(os.path.join(folder, save_fake_images(0)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport os\nfrom IPython.display import FileLink\n\nvid_fname = 'gans_training.avi'\n\nfiles = [os.path.join(folder, f) for f in os.listdir(folder) if 'fake_images' in f]\nfiles.sort()\n\nout = cv2.VideoWriter(vid_fname,cv2.VideoWriter_fourcc(*'MP4V'), 8, (302,302))\n[out.write(cv2.imread(fname)) for fname in files]\nout.release()\nFileLink('gans_training.avi')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
